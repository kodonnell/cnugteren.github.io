---
layout: default
title: Cedric Nugteren | CLBlast
current: 4
redirect_from:
 - /clblast.html
 - /clblast/
---

<h1>CLBlast: The tuned OpenCL BLAS library</h1>

<div class="text">
	CLBlast is a modern, lightweight, performant and tunable OpenCL BLAS library written in C++11. It is designed to leverage the full performance potential of a wide variety of OpenCL devices from different vendors, including desktop and laptop GPUs, embedded GPUs, and other accelerators. CLBlast implements BLAS routines: basic linear algebra subprograms operating on vectors and matrices.
	<br/><br/>
	The library is not tuned for all possible OpenCL devices: if out-of-the-box performance is poor, please run the tuners first. See <a href=https://github.com/CNugteren/CLBlast#using-the-tuners-optional>the README on GitHub</a> for a list of already tuned devices and instructions on how to tune yourself and contribute to future releases of the CLBlast library.
	<br/><br/>
	View on <a href=https://github.com/CNugteren/CLBlast>CLBlast on GitHub</a>.
</div>

<h2>Why CLBlast and not clBLAS or cuBLAS?</h2>

<div class="text">
	Use CLBlast instead of clBLAS:
	<ol>
		<li>When you care about achieving maximum performance.</li>
		<li>When you want to be able to inspect the BLAS kernels or easily customize them to your needs.</li>
		<li>When you run on exotic OpenCL devices for which you need to tune yourself.</li>
		<li>When you are still running on OpenCL 1.1 hardware.</li>
		<li>When you prefer a C++ API over a C API (C API also available in CLBlast).</li>
		<li>When you value an organized and modern C++ codebase.</li>
		<li>When you target Intel CPUs and GPUs or embedded devices.</li>
		<li>When you can benefit from the increased performance of half-precision fp16 data-types.</li>
	</ol>

	Use CLBlast instead of cuBLAS:
	<ol>
		<li>When you want your code to run on devices other than NVIDIA CUDA-enabled GPUs.</li>
		<li>When you want to tune for a specific configuration (e.g. rectangular matrix-sizes).</li>
		<li>When you sleep better if you know that the library you use is open-source.</li>
		<li>When you are using OpenCL rather than CUDA.</li>
	</ol>

	When not to use CLBlast:
	<ol>
		<li>When you run on NVIDIA's CUDA-enabled GPUs only and can benefit from cuBLAS's assembly-level tuned kernels.</li>
	</ol>
</div>

<h2>Benchmark results</h2>

<div class="text">
	Several benchmarks have been performed using CLBlast's clients and benchmarking script. Below are resuls for various devices:
	<ol>
		<li><a href='/clblast/clblast.html'>- Main page</a></li>
		<li><a href='/clblast/results/gtx750ti.html'>- NVIDIA GeForce GTX750Ti</a></li>
		<li><a href='/clblast/results/titanxpascal.html'>- NVIDIA Titan X (Pascal)</a></li>
		<li><a href='/clblast/results/m370x.html'>- AMD Radeon M370X</a></li>
		<li><a href='/clblast/results/tahiti.html'>- AMD Radeon HD7970</a></li>
		<li><a href='/clblast/results/irispro.html'>- Intel Iris Pro 5100</a></li>
		<li><a href='/clblast/results/skylakeultgt2.html'>- Intel Skylake ULT GT2</a></li>
		<li><a href='/clblast/results/i56200u.html'>- Intel Core i5-6200U</a></li>
		<li><a href='/clblast/results/mali.html'>- ARM Mali T628</a></li>
	</ol>
</div>

<h1>News</h1>

<h2>January 29, 2018: CLBlast 1.3.0 released</h2>

A new CLBlast is released, including bug fixes, a new integrated auto-tuner, API additions for advanced users, improved performance on Mali GPUs, and a new strided-batched routine. The <a href="https://github.com/CNugteren/CLBlast/releases">changelog and download links are published on GitHub</a>.

<h2>November 8, 2017: CLBlast 1.2.0 released</h2>

A new CLBlast is released, including bug fixes, a CUDA back-end and better GEMM performance. The <a href="https://github.com/CNugteren/CLBlast/releases">changelog and download links are published on GitHub</a>.

<h2>September 30, 2017: CLBlast 1.1.0 released</h2>

A new CLBlast is released, including bug fixes, a per-architecture tuning database, and the new im2col routine. The <a href="https://github.com/CNugteren/CLBlast/releases">changelog and download links are published on GitHub</a>.

<h2>July 30, 2017: CLBlast 1.0.0 released</h2>

CLBlast is mature enough to be released as version 1.0! The <a href="https://github.com/CNugteren/CLBlast/releases">changelog and download links are published on GitHub</a>.

<h2>May 21, 2017: CLBlast paper published on arXiv.org</h2>

A technical article on CLBlast was <a href="https://arxiv.org/abs/1705.05249">published on the open-access arXiv.org platform</a>. The article is titled "CLBlast: A Tuned OpenCL BLAS Library" and discusses the library design and several of the most interesting performance results. The <a href="https://arxiv.org/pdf/1705.05249">full 8-page PDF</a> is freely available on <a href="https://arxiv.org/abs/1705.05249">arXiv.org</a>.

<h2>May 3, 2017: Presenting CLBlast at GTC '17</h2>

CLBlast will be presented one week from now at the <a href="http://www.gputechconf.com/">GPU Technology Conference</a> in San Jose. For an abstract and more details about the 25 minute talk, see <a href="https://gputechconf2017.smarteventscloud.com/connect/sessionDetail.ww?SESSION_ID=109972&tclass=popup">the GTC website</a>. Slides and video will be made available after the conference.

<h2>May 2, 2017: CLBlast 0.11.0 released</h2>

Preview version 0.11.0 of CLBlast was released today. The <a href="https://github.com/CNugteren/CLBlast/releases">changelog and download links are published on GitHub</a>.

<h2>April 23, 2017: Added benchmark results</h2>

An initial set of benchmark results for 6 devices was uploaded, see the navigation links on the left.

<h2>April 20, 2017: Launch of this page</h2>

First version of this page is created. In the future it will host performance benchmark results for the CLBlast library on various devices.
